{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flower Species Classification\n",
    "In this project, we'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='./flower_data/assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n",
    "\n",
    "\n",
    "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzmPIihoVLug"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Here we'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). The dataset is split into two parts, training and validation. For the training, we'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. \n",
    "\n",
    "The validation set is used to measure the model's performance on data it hasn't seen yet. For this we don't want any scaling or rotation transformations, but we'll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks available from `torchvision` were trained on the ImageNet dataset where each color channel was normalized separately. For both sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLNbBbXQVp0i"
   },
   "outputs": [],
   "source": [
    "dirc = '/flower_data'\n",
    "train_dir = dirc + '/train'\n",
    "valid_dir = dirc + '/valid'\n",
    "\n",
    "train_transform = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "valid_transform = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform = train_transform)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform = valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dyl60OUKWK5X"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KwOUc6L5KgIf"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./flower_data/cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0JoEmV6NIjq"
   },
   "outputs": [],
   "source": [
    "#DISPLAY Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def im_convert(tensor):\n",
    "    \"\"\" Display a tensor as an image. \"\"\"\n",
    "    \n",
    "    image = tensor.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "\n",
    "    return image\n",
    "  \n",
    "fig, (ax1) = plt.subplots(1, figsize=(10, 10))\n",
    "# content and style ims side-by-side\n",
    "ax1.imshow(im_convert(images[11]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "Now we build the model.\n",
    "Here, we use the pretrained Densenet-121 model and only build the classifier to the model. The following are the steps to be taken:\n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) \n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QcxXSHi7NrMB"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "model = models.densenet121(pretrained=True)\n",
    "#model.aux_logits=False\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "print(model.classifier.out_features)\n",
    "n_inputs = model.classifier.in_features\n",
    "n_outputs = 102\n",
    "last_layer = nn.Linear(n_inputs, n_outputs)\n",
    "model.classifier = last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuKvdK85pmC4"
   },
   "outputs": [],
   "source": [
    "for param in model.classifier.parameters():\n",
    "  param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srsFcWe9Uxiv"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.001\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORM5NCLff_XD"
   },
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4441566,
     "status": "ok",
     "timestamp": 1547053196496,
     "user": {
      "displayName": "Raashid Tak",
      "photoUrl": "",
      "userId": "07736395178387181349"
     },
     "user_tz": -330
    },
    "id": "IRuDL2yEdgNW",
    "outputId": "ec58697e-2816-48bf-a6bf-220db5707ca7"
   },
   "outputs": [],
   "source": [
    "\n",
    "n_epochs = 30\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    for data, target in trainloader:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "          data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        output = model(data)        \n",
    "        loss = criterion(output, target)        \n",
    "        loss.backward()        \n",
    "        optimizer.step()       \n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "   \n",
    "    model.eval()\n",
    "    for data, target in testloader:\n",
    "        \n",
    "        \n",
    "        if train_on_gpu:\n",
    "          data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        output = model(data)        \n",
    "        loss = criterion(output, target)         \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    \n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "    valid_loss = valid_loss/len(testloader.dataset)\n",
    "        \n",
    "   \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "   \n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9_4GzbpfMWH"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "model.cpu()\n",
    "#images.cuda()\n",
    "#labels.cuda()\n",
    "output = model(images)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1072,
     "status": "ok",
     "timestamp": 1547055976366,
     "user": {
      "displayName": "Raashid Tak",
      "photoUrl": "",
      "userId": "07736395178387181349"
     },
     "user_tz": -330
    },
    "id": "qvBXROaLWlhz",
    "outputId": "49b5eae6-f2d4-4f7e-f752-8ed2b97d9cb4"
   },
   "outputs": [],
   "source": [
    "test = models.densenet121(pretrained = False)\n",
    "classify = nn.Linear(test.classifier.in_features, 102)\n",
    "test.classifier = classify\n",
    "state_dict = torch.load('model_cifar.pt')\n",
    "test.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-3O9A15sZn_"
   },
   "outputs": [],
   "source": [
    "for param in test.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bnlzbd3AstlK"
   },
   "outputs": [],
   "source": [
    "rl = 0.0\n",
    "if train_on_gpu:\n",
    "  test.cuda()\n",
    "test.eval()\n",
    "for data, labels in trainloader:\n",
    "  \n",
    "  data, labels = data.cuda(), labels.cuda()\n",
    "  output = test(data)\n",
    "  \n",
    "  _, pred = torch.max(output, 1)\n",
    "  rl += torch.sum(pred == labels.data)\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1338,
     "status": "ok",
     "timestamp": 1547056421703,
     "user": {
      "displayName": "Raashid Tak",
      "photoUrl": "",
      "userId": "07736395178387181349"
     },
     "user_tz": -330
    },
    "id": "FdHg4CQpt7RH",
    "outputId": "49126626-4fa1-40a6-a6f8-2c2e6889ce3e"
   },
   "outputs": [],
   "source": [
    "acc = rl.double()/len(testloader.dataset)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1249,
     "status": "ok",
     "timestamp": 1547056257769,
     "user": {
      "displayName": "Raashid Tak",
      "photoUrl": "",
      "userId": "07736395178387181349"
     },
     "user_tz": -330
    },
    "id": "SJVJW4IZupiX",
    "outputId": "495fabf0-8082-415f-f421-856f599bb938"
   },
   "outputs": [],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TB2wgECfvRWg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
